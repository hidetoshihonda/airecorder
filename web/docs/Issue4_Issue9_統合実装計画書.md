# Issue #4 Phase 2 + Issue #9 çµ±åˆå®Ÿè£…è¨ˆç”»æ›¸
# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° Ã— è©±è€…è­˜åˆ¥ï¼ˆConversationTranscriberï¼‰

**Issue**: [#4](https://github.com/hidetoshihonda/airecorder/issues/4) + [#9](https://github.com/hidetoshihonda/airecorder/issues/9)  
**ä½œæˆæ—¥**: 2026-02-08  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: è¨ˆç”»  
**ãƒ–ãƒ©ãƒ³ãƒ**: `feature/segment-rendering-with-diarization`

---

## 1. ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼

Issue #4 Phase 2ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹ã‚¹ãƒ ãƒ¼ã‚ºè¡¨ç¤ºï¼‰ã¨ Issue #9ï¼ˆConversationTranscriber ã«ã‚ˆã‚‹è©±è€…è­˜åˆ¥ï¼‰ã¯ã€**transcript ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ `string` â†’ æ§‹é€ åŒ–ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—ã«å¤‰æ›´ã™ã‚‹** ã¨ã„ã†åŒä¸€ã®åŸºç›¤ä½œæ¥­ã‚’å¿…è¦ã¨ã™ã‚‹ã€‚

ã“ã‚Œã‚‰ã‚’**åˆ¥ã€…ã«å®Ÿè£…ã™ã‚‹ã¨**ï¼š
1. Phase 2 ã§ `segments: string[]` ã«å¤‰æ›´ â†’ Issue #9 ã§ `segments: LiveSegment[]` ã«å†å¤‰æ›´ï¼ˆ**äºŒåº¦æ‰‹é–“**ï¼‰
2. useSpeechRecognition ã®å¤§æ”¹ä¿®ãŒ **2å›** å¿…è¦ã«ãªã‚‹
3. page.tsx ã®è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã‚‚ **2å›** æ›¸ãæ›ãˆãŒç™ºç”Ÿã™ã‚‹

æœ¬è¨ˆç”»ã§ã¯ã€**ä¸€åº¦ã®åŸºç›¤è¨­è¨ˆã§ä¸¡æ–¹ã‚’åŒæ™‚ã«å®Ÿç¾ã™ã‚‹**ã€‚

### çµ±åˆã«ã‚ˆã‚‹åŠ¹æœ

| é …ç›® | å€‹åˆ¥å®Ÿè£… | çµ±åˆå®Ÿè£… | å‰Šæ¸› |
|---|---|---|---|
| useSpeechRecognition æ”¹ä¿®å›æ•° | 2å› | **1å›** | -50% |
| page.tsx è¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯å¤‰æ›´å›æ•° | 2å› | **1å›** | -50% |
| åˆè¨ˆå·¥æ•° | ~20h (65min + 19h) | **~16h** | -20% |
| ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯ | é«˜ï¼ˆ2å›ã®ç ´å£Šçš„å¤‰æ›´ï¼‰ | **ä½ï¼ˆ1å›ã®å¤‰æ›´ï¼‰** | â€” |

---

## 2. ç¾çŠ¶ã®å•é¡Œã¨çµ±åˆã‚´ãƒ¼ãƒ«

### 2.1 Issue #4 Phase 2 ã®èª²é¡Œ

```
ç¾çŠ¶: transcript = "ã“ã‚“ã«ã¡ã¯ã€‚ ä»Šæ—¥ã®ä¼šè­°ã‚’å§‹ã‚ã¾ã™ã€‚ ..."  (å˜ä¸€ string)
       â†“ React ãŒå…¨ä½“ã‚’å†æç”» â†’ ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãƒ»ã¡ã‚‰ã¤ã
```

### 2.2 Issue #9 ã®èª²é¡Œ

```
ç¾çŠ¶: enableSpeakerDiarization = true ã®å ´åˆ
      â†’ æ²ˆé»™æ™‚é–“2ç§’ã§è©±è€…ã‚’æ¨å®šï¼ˆä¸æ­£ç¢ºï¼‰
      â†’ Azure ConversationTranscriber ã‚’ä½¿ãˆã°å£°ç´‹ãƒ™ãƒ¼ã‚¹ã®æ­£ç¢ºãªè­˜åˆ¥ãŒå¯èƒ½
```

### 2.3 çµ±åˆå¾Œã®ã‚´ãƒ¼ãƒ«

```
After:  segments = [
          { id: "seg-1", text: "ã“ã‚“ã«ã¡ã¯ã€‚", speaker: "Guest-1", timestamp: 0 },
          { id: "seg-2", text: "å§‹ã‚ã¾ã—ã‚‡ã†ã€‚", speaker: "Guest-2", timestamp: 5200 },
          ...
        ]
        â†“ React ãŒæ–°ã—ã„ <div key="seg-2"> ã ã‘ã‚’è¿½åŠ ï¼ˆæ—¢å­˜ DOM ä¸å¤‰ï¼‰
        â†“ è©±è€…ã”ã¨ã«è‰²åˆ†ã‘ã•ã‚ŒãŸãƒãƒ–ãƒ«è¡¨ç¤º
        â†“ overflow-anchor ã§ãƒ–ãƒ©ã‚¦ã‚¶ãƒã‚¤ãƒ†ã‚£ãƒ–è¿½å¾“
```

---

## 3. çµ±åˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

### 3.1 æ–°ã—ã„ LiveSegment å‹

```typescript
// types/index.ts ã«è¿½åŠ 
export interface LiveSegment {
  /** ãƒ¦ãƒ‹ãƒ¼ã‚¯ IDï¼ˆReact key ã¨ã—ã¦ä½¿ç”¨ï¼‰ */
  id: string;
  /** ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆ */
  text: string;
  /** è©±è€… IDï¼ˆConversationTranscriber: "Guest-1" ç­‰ã€é€šå¸¸ãƒ¢ãƒ¼ãƒ‰: undefinedï¼‰ */
  speaker?: string;
  /** è©±è€…ãƒ©ãƒ™ãƒ«ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè¨­å®šã—ãŸè¡¨ç¤ºåã€ä¾‹: "ç”°ä¸­ã•ã‚“"ï¼‰ */
  speakerLabel?: string;
  /** ç™ºè©±é–‹å§‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆms, éŒ²éŸ³é–‹å§‹ã‹ã‚‰ã®ç›¸å¯¾ï¼‰ */
  timestamp: number;
  /** ç™ºè©±æ™‚é–“ï¼ˆmsï¼‰ */
  duration?: number;
}
```

### 3.2 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä¾å­˜é–¢ä¿‚ï¼ˆAfterï¼‰

```
page.tsx (HomePage)
â”œâ”€â”€ useSpeechRecognition() â† å¤§æ”¹ä¿®
â”‚   â”œâ”€â”€ mode: "standard" â†’ SpeechRecognizerï¼ˆå¾“æ¥é€šã‚Šï¼‰
â”‚   â”‚   â””â”€â”€ return: segments: LiveSegment[] (speaker=undefined)
â”‚   â”œâ”€â”€ mode: "diarization" â†’ ConversationTranscriberï¼ˆæ–°è¦ï¼‰
â”‚   â”‚   â””â”€â”€ return: segments: LiveSegment[] (speaker="Guest-N")
â”‚   â”œâ”€â”€ transcript: string (= segments.map(s => s.text).join(" "), derived)
â”‚   â””â”€â”€ interimTranscript: string (å¤‰æ›´ãªã—)
â”‚
â”œâ”€â”€ useSpeakerManager() â† æ–°è¦ãƒ•ãƒƒã‚¯
â”‚   â”œâ”€â”€ speakers: Map<string, SpeakerInfo>
â”‚   â”œâ”€â”€ renameSpeaker(id, label): void
â”‚   â””â”€â”€ getSpeakerColor(id): SpeakerColor
â”‚
â”œâ”€â”€ <TranscriptView /> â† æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
â”‚   â”œâ”€â”€ segments: LiveSegment[] ã‚’å—ã‘å–ã‚Š
â”‚   â”œâ”€â”€ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆå·®åˆ† DOM æ›´æ–°ï¼‰
â”‚   â”œâ”€â”€ è©±è€…ã”ã¨ã®è‰²åˆ†ã‘ãƒãƒ–ãƒ«è¡¨ç¤º
â”‚   â”œâ”€â”€ overflow-anchor ã«ã‚ˆã‚‹è‡ªå‹•è¿½å¾“
â”‚   â””â”€â”€ autoFollow / Follow ãƒˆã‚°ãƒ«
â”‚
â”œâ”€â”€ ä¿å­˜ãƒ»ç¿»è¨³ãƒ»ã‚³ãƒ”ãƒ¼ãƒ»è­°äº‹éŒ² â†’ transcript (string) ã‚’ä½¿ç”¨ï¼ˆå¤‰æ›´ãªã—ï¼‰
â””â”€â”€ ç¿»è¨³ã‚¿ãƒ– â†’ translatedText è¡¨ç¤ºï¼ˆscroll æ”¹å–„ã®ã¿ï¼‰
```

### 3.3 ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆAfterï¼‰

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  enableDiarization = false  â”‚
                    â”‚  â†’ SpeechRecognizer         â”‚
                    â”‚  recognized event:          â”‚
                    â”‚    setSegments(prev => [    â”‚
                    â”‚      ...prev,               â”‚
                    â”‚      { id, text }           â”‚ â† speaker ãªã—
                    â”‚    ])                        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
 Azure Speech SDK â”€â”€â†’ useSpeechRecognition â”€â”€â†’ segments: LiveSegment[]
                                 â”‚                       â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
                    â”‚  enableDiarization = true   â”‚       â”‚
                    â”‚  â†’ ConversationTranscriber  â”‚       â”‚
                    â”‚  transcribed event:         â”‚       â”‚
                    â”‚    setSegments(prev => [    â”‚       â”‚
                    â”‚      ...prev,               â”‚       â”‚
                    â”‚      { id, text, speaker,   â”‚       â”‚
                    â”‚        timestamp, duration } â”‚       â”‚
                    â”‚    ])                        â”‚       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
                                                          â”‚
                                                          â–¼
                                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                              â”‚  page.tsx             â”‚
                                              â”‚                      â”‚
                                              â”‚  transcript =        â”‚
                                              â”‚   segments           â”‚
                                              â”‚    .map(s => s.text) â”‚
                                              â”‚    .join(" ")        â”‚
                                              â”‚  (derived, å¾Œæ–¹äº’æ›) â”‚
                                              â”‚                      â”‚
                                              â”‚  <TranscriptView     â”‚
                                              â”‚    segments={segments}â”‚
                                              â”‚    speakers={...}    â”‚
                                              â”‚  />                  â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º

### Phase A: åŸºç›¤ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—åŒ– + ã‚¹ãƒ ãƒ¼ã‚ºãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼‰

Issue #4 Phase 2 ã®æ ¸å¿ƒã€‚**è©±è€…è­˜åˆ¥ã‚’æœ‰åŠ¹ã«ã—ãªãã¦ã‚‚æ©æµãŒã‚ã‚‹**ã€‚

### Phase B: ConversationTranscriber çµ±åˆ

Issue #9 ã®æ ¸å¿ƒã€‚Phase A ã®åŸºç›¤ã®ä¸Šã«æ§‹ç¯‰ã€‚

### Phase C: è©±è€…ç®¡ç† UI + ãƒ©ãƒ™ãƒªãƒ³ã‚°

Issue #9 ã® UX å±¤ã€‚

### Phase D: æ—¢å­˜æ©Ÿèƒ½ã¨ã®çµ±åˆãƒ»ç£¨ãä¸Šã’

ç¿»è¨³ãƒ»ä¿å­˜ãƒ»è­°äº‹éŒ²ã¨ã®é€£æºã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã€‚

---

## 5. è©³ç´°å®Ÿè£…è¨ˆç”»

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### Phase A: åŸºç›¤ï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—åŒ–ï¼‰â€” ç´„2æ™‚é–“
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#### Step A-1: `LiveSegment` å‹ã®å®šç¾©

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/types/index.ts`

```typescript
// æ—¢å­˜ã® TranscriptSegment ã¨ã¯åˆ¥ã«ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºç”¨ã®å‹ã‚’å®šç¾©
// TranscriptSegment ã¯ä¿å­˜æ¸ˆã¿ Recording ç”¨ã€LiveSegment ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”¨
export interface LiveSegment {
  id: string;
  text: string;
  speaker?: string;
  speakerLabel?: string;
  timestamp: number;
  duration?: number;
}
```

**ç†ç”±**: æ—¢å­˜ã® `TranscriptSegment`ï¼ˆ`types/index.ts` L23ï¼‰ã¯ä¿å­˜ç”¨ã®å‹ï¼ˆ`startTime`, `endTime`, `confidence` ã‚’æŒã¤ï¼‰ã§ã‚ã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã«å¿…è¦ãª `speaker` ã®æ‰±ã„ãŒç•°ãªã‚‹ã€‚è²¬å‹™åˆ†é›¢ã®ãŸã‚æ–°ã—ã„å‹ã‚’ä½œã‚‹ã€‚

**å·¥æ•°**: 5åˆ†

---

#### Step A-2: `useSpeechRecognition.ts` â€” segments ã‚’ Primary Data ã«

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useSpeechRecognition.ts`

##### å¤‰æ›´ç‚¹1: state ã®å¤‰æ›´

```typescript
// Before
const [transcript, setTranscript] = useState("");
const [transcriptSegments, setTranscriptSegments] = useState<TranscriptSegment[]>([]);

// After
const [segments, setSegments] = useState<LiveSegment[]>([]);
const segmentIdRef = useRef(0);
// transcript ã¯ derived
const transcript = useMemo(
  () => segments.map(s => s.text).join(" "),
  [segments]
);
// transcriptSegments ã¯å¾Œæ–¹äº’æ›ã§ç¶­æŒï¼ˆè©±è€…è­˜åˆ¥ã®æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ç”¨ï¼‰
const [transcriptSegments, setTranscriptSegments] = useState<TranscriptSegment[]>([]);
```

##### å¤‰æ›´ç‚¹2: recognized ã‚¤ãƒ™ãƒ³ãƒˆãƒãƒ³ãƒ‰ãƒ©

```typescript
recognizer.recognized = (_sender, event) => {
  if (event.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
    const newText = event.result.text;
    const now = Date.now();

    // LiveSegment ã‚’è¿½åŠ ï¼ˆè©±è€…è­˜åˆ¥ãªã—ãƒ¢ãƒ¼ãƒ‰ï¼‰
    setSegments(prev => [
      ...prev,
      {
        id: `seg-${++segmentIdRef.current}`,
        text: newText,
        timestamp: now - startTimeRef.current,
      },
    ]);

    setInterimTranscript("");

    // è©±è€…è­˜åˆ¥ã®æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆenableSpeakerDiarization æ™‚ã®ã¿ã€å¾Œæ–¹äº’æ›ï¼‰
    if (enableSpeakerDiarization) {
      // ... existing logic for transcriptSegments ...
    }
  }
};
```

##### å¤‰æ›´ç‚¹3: return ã®æ‹¡å¼µ

```typescript
return {
  isListening,
  isPaused,
  transcript,              // string (derived from segments)
  segments,                // â˜… æ–°è¦: LiveSegment[]
  transcriptSegments,      // å¾Œæ–¹äº’æ›
  interimTranscript,
  error,
  startListening,
  stopListening,
  pauseListening,
  resumeListening,
  resetTranscript,
};
```

##### å¤‰æ›´ç‚¹4: resetTranscript

```typescript
const resetTranscript = useCallback(() => {
  setSegments([]);
  segmentIdRef.current = 0;
  setTranscriptSegments([]);
  setInterimTranscript("");
  pausedTranscriptRef.current = "";
  currentSpeakerRef.current = "è©±è€…1";
}, []);
```

**å·¥æ•°**: 20åˆ†

---

#### Step A-3: `TranscriptView` ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/components/TranscriptView.tsx`ï¼ˆæ–°è¦ï¼‰

```tsx
"use client";

import { useRef, useEffect, useCallback, useState, memo } from "react";
import { ArrowDown } from "lucide-react";
import { LiveSegment } from "@/types";

// è©±è€…ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆï¼ˆIssue #9 ã§ä½¿ç”¨ã€è©±è€…ãªã—æ™‚ã¯ä¸ä½¿ç”¨ï¼‰
const SPEAKER_COLORS = [
  { bg: "bg-blue-50", border: "border-l-blue-400", label: "text-blue-700" },
  { bg: "bg-green-50", border: "border-l-green-400", label: "text-green-700" },
  { bg: "bg-purple-50", border: "border-l-purple-400", label: "text-purple-700" },
  { bg: "bg-orange-50", border: "border-l-orange-400", label: "text-orange-700" },
  { bg: "bg-pink-50", border: "border-l-pink-400", label: "text-pink-700" },
  { bg: "bg-cyan-50", border: "border-l-cyan-400", label: "text-cyan-700" },
  { bg: "bg-yellow-50", border: "border-l-yellow-400", label: "text-yellow-700" },
  { bg: "bg-red-50", border: "border-l-red-400", label: "text-red-700" },
];

function getSpeakerColorIndex(speakerId: string): number {
  // "Guest-1" â†’ 0, "Guest-2" â†’ 1, ...
  const match = speakerId.match(/(\d+)/);
  if (match) return (parseInt(match[1]) - 1) % SPEAKER_COLORS.length;
  return 0;
}

/** å€‹åˆ¥ã‚»ã‚°ãƒ¡ãƒ³ãƒˆï¼ˆmemo ã§å†æç”»ã‚’é˜²æ­¢ï¼‰ */
const SegmentItem = memo(function SegmentItem({
  segment,
  showSpeaker,
}: {
  segment: LiveSegment;
  showSpeaker: boolean;
}) {
  if (!showSpeaker || !segment.speaker) {
    // è©±è€…ãªã—ãƒ¢ãƒ¼ãƒ‰: ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
    return <span className="inline">{segment.text} </span>;
  }

  // è©±è€…ã‚ã‚Šãƒ¢ãƒ¼ãƒ‰: ãƒãƒ–ãƒ«è¡¨ç¤º
  const color = SPEAKER_COLORS[getSpeakerColorIndex(segment.speaker)];
  const label = segment.speakerLabel || segment.speaker;

  return (
    <div className={`rounded-md p-3 mb-2 border-l-4 ${color.bg} ${color.border}`}>
      <div className="flex items-center gap-2 mb-1">
        <span className={`text-xs font-bold ${color.label}`}>{label}</span>
        {segment.timestamp !== undefined && (
          <span className="text-xs text-gray-400">
            {formatTimestamp(segment.timestamp)}
          </span>
        )}
      </div>
      <p className="text-gray-800 text-sm">{segment.text}</p>
    </div>
  );
});

function formatTimestamp(ms: number): string {
  const totalSec = Math.floor(ms / 1000);
  const min = Math.floor(totalSec / 60);
  const sec = totalSec % 60;
  return `${min.toString().padStart(2, "0")}:${sec.toString().padStart(2, "0")}`;
}

interface TranscriptViewProps {
  segments: LiveSegment[];
  interimTranscript: string;
  showSpeaker: boolean;
  isRecording: boolean;
  maxHeight?: string;
}

export function TranscriptView({
  segments,
  interimTranscript,
  showSpeaker,
  isRecording,
  maxHeight = "400px",
}: TranscriptViewProps) {
  const scrollRef = useRef<HTMLDivElement>(null);
  const anchorRef = useRef<HTMLDivElement>(null);
  const [autoFollow, setAutoFollow] = useState(true);

  // Auto-scroll with rAF
  useEffect(() => {
    if (autoFollow && scrollRef.current) {
      requestAnimationFrame(() => {
        if (scrollRef.current) {
          scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
        }
      });
    }
  }, [segments.length, interimTranscript, autoFollow]);

  // Reset autoFollow when recording starts
  useEffect(() => {
    if (isRecording) {
      setAutoFollow(true);
    }
  }, [isRecording]);

  // Manual scroll detection
  const handleScroll = useCallback(
    (e: React.UIEvent<HTMLDivElement>) => {
      const el = e.currentTarget;
      const isAtBottom = el.scrollHeight - el.scrollTop - el.clientHeight < 50;
      if (!isAtBottom && autoFollow) {
        setAutoFollow(false);
      }
    },
    [autoFollow]
  );

  const hasSpeakers = showSpeaker && segments.some((s) => s.speaker);

  return (
    <div className="relative">
      <div
        ref={scrollRef}
        onScroll={handleScroll}
        style={{ maxHeight }}
        className="overflow-y-auto"
      >
        {segments.length > 0 && (
          <div
            className={
              hasSpeakers
                ? "space-y-0"
                : "whitespace-pre-wrap rounded-md bg-gray-50 p-4 text-gray-800"
            }
          >
            {segments.map((seg) => (
              <SegmentItem key={seg.id} segment={seg} showSpeaker={hasSpeakers} />
            ))}
          </div>
        )}

        {interimTranscript && (
          <div className="whitespace-pre-wrap rounded-md bg-blue-50 p-4 text-blue-600 italic mt-1">
            {interimTranscript}
          </div>
        )}

        {/* Scroll anchor for overflow-anchor */}
        <div ref={anchorRef} className="h-px" style={{ overflowAnchor: "auto" }} />
      </div>

      {/* Follow toggle button */}
      {!autoFollow && (
        <div className="flex justify-center mt-2">
          <button
            onClick={() => setAutoFollow(true)}
            className="flex items-center gap-1 rounded-full bg-blue-600 px-4 py-2 text-sm text-white shadow-lg hover:bg-blue-700 transition-colors"
          >
            <ArrowDown className="h-4 w-4" />
            æœ€æ–°ã«è¿½å¾“
          </button>
        </div>
      )}
    </div>
  );
}
```

**è¨­è¨ˆãƒã‚¤ãƒ³ãƒˆ**:
- `SegmentItem` ã‚’ `memo` ã§ãƒ©ãƒƒãƒ— â†’ æ—¢å­˜ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯**çµ¶å¯¾ã«å†æç”»ã•ã‚Œãªã„**
- `showSpeaker=false` æ™‚ã¯ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ `<span>` ã§å¾“æ¥ã¨åŒã˜è¦‹ãŸç›®
- `showSpeaker=true` æ™‚ã¯è©±è€…ã”ã¨ã®ã‚«ãƒ©ãƒ¼ãƒãƒ–ãƒ«è¡¨ç¤º
- `overflow-anchor` ã®ã‚¢ãƒ³ã‚«ãƒ¼è¦ç´ ã§ JS ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‡¦ç†ã‚’æœ€å°åŒ–
- `rAF` ã§ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’æç”»ã‚µã‚¤ã‚¯ãƒ«ã«åˆã‚ã›ã‚‹

**å·¥æ•°**: 30åˆ†

---

#### Step A-4: `page.tsx` â€” TranscriptView å°å…¥

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/app/page.tsx`

##### å¤‰æ›´ç‚¹1: import ã®è¿½åŠ 

```typescript
import { TranscriptView } from "@/components/TranscriptView";
```

##### å¤‰æ›´ç‚¹2: ãƒ•ãƒƒã‚¯å‘¼ã³å‡ºã—

```typescript
const {
  isListening,
  isPaused,
  transcript,
  segments,                // â˜… æ–°è¦
  interimTranscript,
  error: speechError,
  // ...
} = useSpeechRecognition({ /* ... */ });
```

##### å¤‰æ›´ç‚¹3: éŒ²éŸ³ä¸­ã®æ–‡å­—èµ·ã“ã—è¡¨ç¤ºã‚’ TranscriptView ã«ç½®æ›

```tsx
{/* Before: ç›´æ¥ {transcript} ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° */}
{/* After: TranscriptView ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ */}
<CardContent>
  {showRecordingUI ? (
    <>
      {segments.length === 0 && !interimTranscript ? (
        <div className="flex items-center justify-center py-8">
          <Spinner size="lg" />
          <span className="ml-2 text-gray-600">éŸ³å£°ã‚’å¾…ã£ã¦ã„ã¾ã™...</span>
        </div>
      ) : (
        <TranscriptView
          segments={segments}
          interimTranscript={interimTranscript}
          showSpeaker={enableSpeakerDiarization}
          isRecording={showRecordingUI}
        />
      )}
    </>
  ) : transcript ? (
    <div className="max-h-[600px] overflow-y-auto whitespace-pre-wrap rounded-md bg-gray-50 p-4 text-gray-800">
      {transcript}
    </div>
  ) : (
    <div className="py-8 text-center text-gray-500">
      éŒ²éŸ³ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™
    </div>
  )}
</CardContent>
```

##### å¤‰æ›´ç‚¹4: autoFollow é–¢é€£ã® state/effect å‰Šé™¤

Phase 1 ã§è¿½åŠ ã—ãŸ `autoFollow`, `transcriptScrollRef`, `translationScrollRef`, `handleScrollContainer`, é–¢é€£ `useEffect` ã‚’**page.tsx ã‹ã‚‰å‰Šé™¤**ã€‚ã“ã‚Œã‚‰ã¯ `TranscriptView` ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã«å†…åŒ…ã•ã‚Œã‚‹ã€‚

##### å¤‰æ›´ç‚¹5: ç¿»è¨³ã‚¿ãƒ–ã® scroll æ”¹å–„

ç¿»è¨³ã‚¿ãƒ–ã¯ `TranscriptView` ã‚’ä½¿ã‚ãªã„ï¼ˆç¿»è¨³ã¯ã‚»ã‚°ãƒ¡ãƒ³ãƒˆå˜ä½ã§ã¯ãªã„ãŸã‚ï¼‰ã€‚ãŸã ã— `scroll-smooth` ã‚’å‰Šé™¤ã— `rAF` ã«å¤‰æ›´ã™ã‚‹ã€‚

**å·¥æ•°**: 25åˆ†

---

#### Step A-5: ãƒ“ãƒ«ãƒ‰ç¢ºèªãƒ»å‹•ä½œãƒ†ã‚¹ãƒˆ

**å·¥æ•°**: 15åˆ†

---

### Phase A åˆè¨ˆ: ç´„2æ™‚é–“
### Phase A å®Œäº†ã§å¾—ã‚‰ã‚Œã‚‹ã‚‚ã®:
- âœ… ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥ãƒ»ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã®å®Œå…¨è§£æ¶ˆ
- âœ… memo ã«ã‚ˆã‚‹ã‚¼ãƒ­å†æç”»ã®å·®åˆ† DOM æ›´æ–°
- âœ… overflow-anchor + rAF ã®ã‚¹ãƒ ãƒ¼ã‚ºè¿½å¾“
- âœ… è©±è€…è­˜åˆ¥ãªã—ã§ã‚‚å‹•ä½œã™ã‚‹åŸºç›¤
- âœ… Issue #4 Phase 2 å®Œäº†

---

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### Phase B: ConversationTranscriber çµ±åˆ â€” ç´„5æ™‚é–“
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#### Step B-0: äº‹å‰æ¤œè¨¼ï¼ˆJapan East å‹•ä½œç¢ºèªï¼‰

ConversationTranscriber ãŒ Japan East ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã§å‹•ä½œã™ã‚‹ã‹ç¢ºèªã€‚

```typescript
// ç°¡æ˜“æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
const speechConfig = SpeechSDK.SpeechConfig.fromSubscription(key, "japaneast");
const audioConfig = SpeechSDK.AudioConfig.fromDefaultMicrophoneInput();
const transcriber = new SpeechSDK.ConversationTranscriber(speechConfig, audioConfig);
transcriber.transcribed = (s, e) => console.log(e.result.speakerId, e.result.text);
transcriber.startTranscribingAsync();
```

**å‹•ã‹ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯**: East US ã«ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¤‰æ›´ã€ã¾ãŸã¯ãƒ—ãƒ­ã‚­ã‚· API çµŒç”±ã§è»¢é€ã€‚

**å·¥æ•°**: 30åˆ†

---

#### Step B-1: `useSpeechRecognition.ts` ã« ConversationTranscriber ãƒ¢ãƒ¼ãƒ‰ã‚’è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useSpeechRecognition.ts`

æ—¢å­˜ã® `enableSpeakerDiarization` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‹•ä½œã‚’å¤‰æ›´ï¼š

```typescript
// enableSpeakerDiarization = false â†’ SpeechRecognizerï¼ˆç¾è¡Œé€šã‚Šï¼‰
// enableSpeakerDiarization = true  â†’ ConversationTranscriberï¼ˆæ–°è¦ï¼‰
```

##### ConversationTranscriber ã®åˆæœŸåŒ–

```typescript
if (enableSpeakerDiarization) {
  const transcriber = new SpeechSDK.ConversationTranscriber(speechConfig, audioConfig);

  // ä¸­é–“çµæœ
  transcriber.transcribing = (_sender, event) => {
    if (event.result.reason === SpeechSDK.ResultReason.RecognizingSpeech) {
      setInterimTranscript(event.result.text);
      // speakerId ã¯ä¸­é–“çµæœã§ã¯ "Unknown" ã«ãªã‚‹å¯èƒ½æ€§ã‚ã‚Š
    }
  };

  // ç¢ºå®šçµæœ
  transcriber.transcribed = (_sender, event) => {
    if (event.result.reason === SpeechSDK.ResultReason.RecognizedSpeech) {
      const newText = event.result.text;
      const speakerId = event.result.speakerId || "Unknown";

      setSegments(prev => [
        ...prev,
        {
          id: `seg-${++segmentIdRef.current}`,
          text: newText,
          speaker: speakerId,
          timestamp: event.result.offset ? event.result.offset / 10000 : Date.now() - startTimeRef.current,
          duration: event.result.duration ? event.result.duration / 10000 : undefined,
        },
      ]);
      setInterimTranscript("");
    }
  };

  transcriber.canceled = (_sender, event) => { /* ... */ };
  transcriber.sessionStopped = () => { /* ... */ };

  transcriberRef.current = transcriber;
  transcriber.startTranscribingAsync(
    () => setIsListening(true),
    (err) => { setError(`è©±è€…è­˜åˆ¥é–‹å§‹ã‚¨ãƒ©ãƒ¼: ${err}`); setIsListening(false); }
  );
}
```

##### ä¸€æ™‚åœæ­¢/å†é–‹ã®åˆ¶é™å¯¾å¿œ

ConversationTranscriber ã«ã¯ `pause/resume` API ãŒå­˜åœ¨ã—ãªã„ã€‚å¯¾ç­–ï¼š

```typescript
const pauseListening = useCallback(() => {
  if (enableSpeakerDiarization && transcriberRef.current) {
    // ConversationTranscriber: åœæ­¢â†’å†ä½œæˆï¼ˆspeakerId ãƒªã‚»ãƒƒãƒˆã®ãƒªã‚¹ã‚¯ã‚ã‚Šï¼‰
    isPausingRef.current = true;
    transcriberRef.current.stopTranscribingAsync(
      () => { setIsPaused(true); setInterimTranscript(""); },
      (err) => { isPausingRef.current = false; setError(`ä¸€æ™‚åœæ­¢ã‚¨ãƒ©ãƒ¼: ${err}`); }
    );
  } else if (recognizerRef.current) {
    // SpeechRecognizer: å¾“æ¥é€šã‚Š
    // ... existing logic ...
  }
}, [enableSpeakerDiarization, isListening, isPaused]);

const resumeListening = useCallback(() => {
  if (enableSpeakerDiarization) {
    // æ–°ã—ã„ ConversationTranscriber ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦å†é–‹
    // âš ï¸ speakerId ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹å¯èƒ½æ€§ â†’ UI ã§è­¦å‘Šè¡¨ç¤º
    startConversationTranscriber(); // å†…éƒ¨ãƒ˜ãƒ«ãƒ‘ãƒ¼
    setIsPaused(false);
  } else if (recognizerRef.current && isPaused) {
    // ... existing logic ...
  }
}, [enableSpeakerDiarization, isPaused]);
```

**åˆ¶é™äº‹é …**: ä¸€æ™‚åœæ­¢â†’å†é–‹ã§ speakerId ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚ã“ã‚Œã¯ Azure SDK ã®åˆ¶é™ã§ã‚ã‚Šã€UI ã«ã€Œä¸€æ™‚åœæ­¢å¾Œã¯è©±è€…ç•ªå·ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€ã¨æ³¨è¨˜ã™ã‚‹ã€‚

**å·¥æ•°**: 2æ™‚é–“

---

#### Step B-2: è¨­å®šç”»é¢ã«è©±è€…è­˜åˆ¥ãƒˆã‚°ãƒ«ã‚’è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/app/settings/page.tsx`

```tsx
<div className="flex items-center gap-3">
  <label className="relative inline-flex items-center cursor-pointer">
    <input
      type="checkbox"
      checked={settings.enableSpeakerDiarization}
      onChange={(e) => updateSettings({ enableSpeakerDiarization: e.target.checked })}
      className="sr-only peer"
    />
    <div className="w-11 h-6 bg-gray-200 ... peer-checked:bg-blue-600" />
    <span className="ml-3 text-sm font-medium text-gray-700">
      è©±è€…è­˜åˆ¥ï¼ˆSpeaker Diarizationï¼‰
    </span>
  </label>
  <p className="text-xs text-gray-500">
    æœ‰åŠ¹ã«ã™ã‚‹ã¨ã€è¤‡æ•°äººã®ç™ºè©±ã‚’å£°ç´‹ã§è‡ªå‹•è­˜åˆ¥ã—ã¾ã™ã€‚
    âš ï¸ ä¸€æ™‚åœæ­¢ãƒ»å†é–‹æ™‚ã«è©±è€…ç•ªå·ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
  </p>
</div>
```

**å·¥æ•°**: 30åˆ†

---

#### Step B-3: `page.tsx` ã§ enableSpeakerDiarization ã‚’è¨­å®šã‹ã‚‰å—ã‘å–ã‚‹

```typescript
const { settings } = useAuth();
const enableSpeakerDiarization = settings.enableSpeakerDiarization ?? false;

const { segments, transcript, interimTranscript, ... } = useSpeechRecognition({
  subscriptionKey: speechConfig.subscriptionKey,
  region: speechConfig.region,
  language: sourceLanguage,
  enableSpeakerDiarization,
});

// TranscriptView ã« showSpeaker ã‚’æ¸¡ã™
<TranscriptView
  segments={segments}
  interimTranscript={interimTranscript}
  showSpeaker={enableSpeakerDiarization}
  isRecording={showRecordingUI}
/>
```

**å·¥æ•°**: 15åˆ†

---

#### Step B-4: UserSettings å‹ã« enableSpeakerDiarization ã‚’è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/types/index.ts`

```typescript
export interface UserSettings {
  defaultSourceLanguage: string;
  defaultTargetLanguages: string[];
  autoSaveRecordings: boolean;
  noiseSuppression: boolean;
  theme: "light" | "dark" | "system";
  audioQuality: "low" | "medium" | "high";
  enableSpeakerDiarization: boolean;  // â˜… è¿½åŠ 
}
```

**å·¥æ•°**: 5åˆ†

---

#### Step B-5: ãƒ“ãƒ«ãƒ‰ç¢ºèªãƒ»å‹•ä½œãƒ†ã‚¹ãƒˆ

2äººã§äº¤äº’ã«è©±ã—ã€ç•°ãªã‚‹ speakerId ã§è­˜åˆ¥ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèªã€‚

**å·¥æ•°**: 30åˆ†

---

### Phase B åˆè¨ˆ: ç´„5æ™‚é–“
### Phase B å®Œäº†ã§å¾—ã‚‰ã‚Œã‚‹ã‚‚ã®:
- âœ… Azure ConversationTranscriber ã«ã‚ˆã‚‹å£°ç´‹ãƒ™ãƒ¼ã‚¹è©±è€…è­˜åˆ¥
- âœ… è©±è€…ã”ã¨ã®ã‚«ãƒ©ãƒ¼ãƒãƒ–ãƒ«è¡¨ç¤º
- âœ… è¨­å®šç”»é¢ã§ã® ON/OFF åˆ‡ã‚Šæ›¿ãˆ
- âœ… å¾“æ¥ãƒ¢ãƒ¼ãƒ‰ï¼ˆè©±è€…ãªã—ï¼‰ã¨ã®å®Œå…¨äº’æ›
- âœ… Issue #9 ã® MVP å®Œäº†

---

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### Phase C: è©±è€…ç®¡ç† UI + ãƒ©ãƒ™ãƒªãƒ³ã‚° â€” ç´„3æ™‚é–“
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#### Step C-1: `useSpeakerManager.ts` ãƒ•ãƒƒã‚¯ä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useSpeakerManager.ts`ï¼ˆæ–°è¦ï¼‰

```typescript
interface SpeakerInfo {
  id: string;           // "Guest-1", etc.
  label: string;        // ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®šåï¼ˆä¾‹: "ç”°ä¸­ã•ã‚“"ï¼‰
  color: number;        // SPEAKER_COLORS ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
  segmentCount: number; // ç™ºè©±å›æ•°
}

interface UseSpeakerManagerReturn {
  speakers: Map<string, SpeakerInfo>;
  renameSpeaker: (id: string, label: string) => void;
  getSpeakerLabel: (id: string) => string;
  updateFromSegments: (segments: LiveSegment[]) => void;
}

export function useSpeakerManager(): UseSpeakerManagerReturn {
  const [speakers, setSpeakers] = useState<Map<string, SpeakerInfo>>(new Map());

  const renameSpeaker = useCallback((id: string, label: string) => {
    setSpeakers(prev => {
      const next = new Map(prev);
      const info = next.get(id);
      if (info) {
        next.set(id, { ...info, label });
      }
      return next;
    });
    // LocalStorage ã«ä¿å­˜
    localStorage.setItem(`speaker-${id}`, label);
  }, []);

  // segments ãŒæ›´æ–°ã•ã‚ŒãŸã‚‰ speaker æƒ…å ±ã‚’åŒæœŸ
  const updateFromSegments = useCallback((segments: LiveSegment[]) => {
    setSpeakers(prev => {
      const next = new Map(prev);
      segments.forEach(seg => {
        if (seg.speaker && !next.has(seg.speaker)) {
          const saved = localStorage.getItem(`speaker-${seg.speaker}`);
          next.set(seg.speaker, {
            id: seg.speaker,
            label: saved || seg.speaker,
            color: next.size,
            segmentCount: 0,
          });
        }
      });
      // segmentCount ã‚’æ›´æ–°
      next.forEach((info, id) => {
        info.segmentCount = segments.filter(s => s.speaker === id).length;
      });
      return next;
    });
  }, []);

  const getSpeakerLabel = useCallback((id: string) => {
    return speakers.get(id)?.label || id;
  }, [speakers]);

  return { speakers, renameSpeaker, getSpeakerLabel, updateFromSegments };
}
```

**å·¥æ•°**: 45åˆ†

---

#### Step C-2: è©±è€…ä¸€è¦§ãƒ‘ãƒãƒ«

`TranscriptView` ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã«æŠ˜ã‚ŠãŸãŸã¿å¯èƒ½ãªè©±è€…ä¸€è¦§ã‚’è¿½åŠ ï¼š

```tsx
{/* è©±è€…ä¸€è¦§ï¼ˆè©±è€…è­˜åˆ¥æœ‰åŠ¹æ™‚ã®ã¿ï¼‰ */}
{showSpeaker && speakers.size > 0 && (
  <div className="mb-3 rounded-md border border-gray-200 p-3">
    <h4 className="text-xs font-semibold text-gray-500 mb-2">è©±è€…ä¸€è¦§</h4>
    <div className="flex flex-wrap gap-2">
      {Array.from(speakers.values()).map(speaker => {
        const color = SPEAKER_COLORS[speaker.color % SPEAKER_COLORS.length];
        return (
          <div key={speaker.id} className={`flex items-center gap-1 rounded-full px-3 py-1 text-xs ${color.bg}`}>
            <span className={`font-bold ${color.label}`}>{speaker.label}</span>
            <span className="text-gray-400">({speaker.segmentCount}å›)</span>
            <button
              onClick={() => {
                const name = prompt("è©±è€…åã‚’å…¥åŠ›", speaker.label);
                if (name) renameSpeaker(speaker.id, name);
              }}
              className="ml-1 text-gray-400 hover:text-gray-600"
            >
              âœï¸
            </button>
          </div>
        );
      })}
    </div>
  </div>
)}
```

**å·¥æ•°**: 45åˆ†

---

#### Step C-3: speakerLabel ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åæ˜ 

`page.tsx` ã§ `useSpeakerManager` ã‚’ä½¿ã„ã€segments ã® speakerLabel ã‚’å‹•çš„ã«è¨­å®šï¼š

```typescript
const { speakers, renameSpeaker, getSpeakerLabel, updateFromSegments } = useSpeakerManager();

// segments ãŒå¤‰ã‚ã£ãŸã‚‰ speaker æƒ…å ±ã‚’åŒæœŸ
useEffect(() => {
  if (enableSpeakerDiarization) {
    updateFromSegments(segments);
  }
}, [segments, enableSpeakerDiarization, updateFromSegments]);

// segments ã« speakerLabel ã‚’ä»˜ä¸ã—ã¦ TranscriptView ã«æ¸¡ã™
const labeledSegments = useMemo(() => {
  if (!enableSpeakerDiarization) return segments;
  return segments.map(seg => ({
    ...seg,
    speakerLabel: seg.speaker ? getSpeakerLabel(seg.speaker) : undefined,
  }));
}, [segments, enableSpeakerDiarization, getSpeakerLabel]);
```

**å·¥æ•°**: 30åˆ†

---

#### Step C-4: ä¿å­˜æ™‚ã«è©±è€…æƒ…å ±ã‚’å«ã‚ã‚‹

`handleSave` ã§ segments ã‚’ä¿å­˜ç”¨ `TranscriptSegment[]` ã«å¤‰æ›ï¼š

```typescript
transcript: {
  segments: segments.map((seg, i) => ({
    id: seg.id,
    speaker: seg.speaker ? (getSpeakerLabel(seg.speaker) || seg.speaker) : undefined,
    text: seg.text,
    startTime: seg.timestamp / 1000,
    endTime: seg.duration ? (seg.timestamp + seg.duration) / 1000 : duration,
  })),
  fullText: transcript,
},
```

**å·¥æ•°**: 15åˆ†

---

#### Step C-5: ãƒ†ã‚¹ãƒˆãƒ»å‹•ä½œç¢ºèª

**å·¥æ•°**: 15åˆ†

---

### Phase C åˆè¨ˆ: ç´„3æ™‚é–“
### Phase C å®Œäº†ã§å¾—ã‚‰ã‚Œã‚‹ã‚‚ã®:
- âœ… è©±è€…ã®ã‚«ã‚¹ã‚¿ãƒ åè¨­å®šï¼ˆã€ŒGuest-1ã€â†’ã€Œç”°ä¸­ã•ã‚“ã€ï¼‰
- âœ… è©±è€…ä¸€è¦§ãƒ‘ãƒãƒ«ã¨ç™ºè©±å›æ•°è¡¨ç¤º
- âœ… LocalStorage ã«ã‚ˆã‚‹è©±è€…åæ°¸ç¶šåŒ–
- âœ… ä¿å­˜æ™‚ã«è©±è€…æƒ…å ±ã‚’å«ã‚€ Transcript ç”Ÿæˆ

---

### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
### Phase D: çµ±åˆãƒ»ç£¨ãä¸Šã’ â€” ç´„3æ™‚é–“
### â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#### Step D-1: ç¿»è¨³ã‚¿ãƒ–ã® scroll æ”¹å–„

ç¿»è¨³ã‚¿ãƒ–ã¯ `TranscriptView` ã‚’ä½¿ã‚ãªã„ï¼ˆç¿»è¨³ API ã¯å…¨æ–‡ä¸€æ‹¬ã®ãŸã‚ï¼‰ãŒã€`scroll-smooth` å‰Šé™¤ + `rAF` + `overflow-anchor` ã‚’é©ç”¨ã€‚

**å·¥æ•°**: 15åˆ†

---

#### Step D-2: è­°äº‹éŒ²ç”Ÿæˆã«è©±è€…æƒ…å ±ã‚’å«ã‚ã‚‹

`summaryApi.generateSummary` ã«æ¸¡ã™ transcript ã‚’è©±è€…ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«ã™ã‚‹ï¼š

```typescript
// è©±è€…è­˜åˆ¥æœ‰åŠ¹æ™‚
const transcriptForSummary = enableSpeakerDiarization
  ? segments.map(s => `[${getSpeakerLabel(s.speaker || "ä¸æ˜")}] ${s.text}`).join("\n")
  : transcript;

const response = await summaryApi.generateSummary({
  transcript: transcriptForSummary,
  language: sourceLanguage,
});
```

ã“ã‚Œã«ã‚ˆã‚Š AI è­°äº‹éŒ²ãŒã€Œç”°ä¸­ã•ã‚“ãŒææ¡ˆã—ã€éˆ´æœ¨éƒ¨é•·ãŒæ‰¿èªã—ãŸã€ã®ã‚ˆã†ãªè©±è€…ã‚’å«ã‚€è­°äº‹éŒ²ã‚’ç”Ÿæˆã§ãã‚‹ã€‚

**å·¥æ•°**: 15åˆ†

---

#### Step D-3: éŒ²éŸ³è©³ç´°ãƒšãƒ¼ã‚¸ï¼ˆrecording/page.tsxï¼‰ã®è©±è€…è¡¨ç¤º

ä¿å­˜æ¸ˆã¿ Recording ã®è¡¨ç¤ºã§ã€`transcript.segments` ã« `speaker` ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã«ãƒãƒ–ãƒ«è¡¨ç¤ºã™ã‚‹ã€‚

**å·¥æ•°**: 30åˆ†

---

#### Step D-4: ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å¯¾å¿œ

| ã‚±ãƒ¼ã‚¹ | å¯¾å¿œ |
|---|---|
| ConversationTranscriber åˆæœŸåŒ–å¤±æ•— | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: SpeechRecognizer ã«åˆ‡ã‚Šæ›¿ãˆ + ã‚¨ãƒ©ãƒ¼é€šçŸ¥ |
| speakerId = "Unknown" ã®ä¸­é–“çµæœ | ã€Œè©±è€…è­˜åˆ¥ä¸­...ã€ã®ãƒ©ãƒ™ãƒ«è¡¨ç¤º |
| pause â†’ resume ã§ speakerId ãƒªã‚»ãƒƒãƒˆ | UI ã«ã‚¤ãƒ³ãƒ•ã‚©ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¡¨ç¤º |
| 1000+ segments ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ | å°†æ¥çš„ã«ä»®æƒ³ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ¤œè¨ï¼ˆPhase Eï¼‰ |

**å·¥æ•°**: 45åˆ†

---

#### Step D-5: å…¨ä½“çµ±åˆãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ»PR

| ãƒ†ã‚¹ãƒˆã‚·ãƒŠãƒªã‚ª | ç¢ºèªäº‹é … |
|---|---|
| è©±è€…è­˜åˆ¥ OFF ã§éŒ²éŸ³ â†’ ä¿å­˜ â†’ ç¿»è¨³ â†’ ã‚³ãƒ”ãƒ¼ â†’ è­°äº‹éŒ² | å…¨å¾Œæ–¹äº’æ› |
| è©±è€…è­˜åˆ¥ ON ã§2äººä¼šè©± â†’ ä¿å­˜ â†’ è­°äº‹éŒ² | è©±è€…åä»˜ãä¿å­˜ãƒ»è­°äº‹éŒ² |
| è©±è€…åã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º â†’ ä¿å­˜ | ã‚«ã‚¹ã‚¿ãƒ åã§ä¿å­˜ã•ã‚Œã‚‹ |
| 30åˆ†éŒ²éŸ³ â†’ ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«å‹•ä½œ | ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ãªã—ãƒ»ã‚¹ãƒ ãƒ¼ã‚º |
| pause â†’ resumeï¼ˆè©±è€…è­˜åˆ¥ ONï¼‰ | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä¿æŒãƒ»è­¦å‘Šè¡¨ç¤º |

**å·¥æ•°**: 45åˆ†

---

### Phase D åˆè¨ˆ: ç´„3æ™‚é–“

---

## 6. å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ï¼ˆå…¨ãƒ•ã‚§ãƒ¼ã‚ºåˆè¨ˆï¼‰

### å¤‰æ›´ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | Phase | å¤‰æ›´å†…å®¹ |
|---|---|---|
| `web/src/types/index.ts` | A | `LiveSegment` å‹è¿½åŠ ã€`UserSettings` ã« `enableSpeakerDiarization` è¿½åŠ  |
| `web/src/hooks/useSpeechRecognition.ts` | A+B | `segments: LiveSegment[]` ã‚’ primary data ã«ã€ConversationTranscriber ãƒ¢ãƒ¼ãƒ‰è¿½åŠ  |
| `web/src/app/page.tsx` | A+B+D | TranscriptView å°å…¥ã€Phase 1 ã® autoFollow é–¢é€£ã‚³ãƒ¼ãƒ‰å‰Šé™¤ã€ç¿»è¨³ scroll æ”¹å–„ |
| `web/src/app/settings/page.tsx` | B | è©±è€…è­˜åˆ¥ãƒˆã‚°ãƒ«è¿½åŠ  |
| `web/src/contexts/AuthContext.tsx` | B | UserSettings ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã« `enableSpeakerDiarization: false` è¿½åŠ  |
| `web/src/app/recording/page.tsx` | D | ä¿å­˜æ¸ˆã¿éŒ²éŸ³ã®è©±è€…ãƒãƒ–ãƒ«è¡¨ç¤º |
| `web/src/services/summaryApi.ts` | D | å¤‰æ›´ãªã—ï¼ˆå‘¼ã³å‡ºã—å´ã§ transcript ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’å¤‰æ›´ï¼‰ |

### æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«

| ãƒ•ã‚¡ã‚¤ãƒ« | Phase | å†…å®¹ |
|---|---|---|
| `web/src/components/TranscriptView.tsx` | A | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° + è©±è€…ãƒãƒ–ãƒ« + auto-scroll |
| `web/src/hooks/useSpeakerManager.ts` | C | è©±è€…ç®¡ç†ãƒ»ãƒ©ãƒ™ãƒªãƒ³ã‚°ãƒ»æ°¸ç¶šåŒ– |

### å¤‰æ›´ä¸è¦ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆå¾Œæ–¹äº’æ›æ€§ï¼‰

| ãƒ•ã‚¡ã‚¤ãƒ« | ç†ç”± |
|---|---|
| `web/src/services/recordingsApi.ts` | `Transcript` å‹ã®æ§‹é€ ã¯å¤‰æ›´ãªã— |
| `web/src/lib/export.ts` | `recording.transcript.fullText` ã§å‹•ä½œ |
| `web/src/hooks/useAudioRecorder.ts` | transcript éä¾å­˜ |
| `web/src/hooks/useRecordingStateMachine.ts` | FSM ã®ã¿ |
| `api/**` | API å´ã¯ transcript æ§‹é€ ã‚’é€éçš„ã«ä¿å­˜ã™ã‚‹ãŸã‚å¤‰æ›´ä¸è¦ |

---

## 7. å…¨ä½“ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

| Phase | ä½œæ¥­å†…å®¹ | è¦‹ç©ã‚Š | å‰æ |
|---|---|---|---|
| **A** | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé…åˆ—åŒ– + TranscriptView + ã‚¹ãƒ ãƒ¼ã‚ºãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚° | **2h** | ãªã— |
| **B** | ConversationTranscriber çµ±åˆ + è¨­å®š UI | **5h** | Phase A + Japan East æ¤œè¨¼ |
| **C** | è©±è€…ç®¡ç† UI + ãƒ©ãƒ™ãƒªãƒ³ã‚° + æ°¸ç¶šåŒ– | **3h** | Phase B |
| **D** | çµ±åˆãƒ»ç£¨ãä¸Šã’ï¼ˆç¿»è¨³/è­°äº‹éŒ²/è©³ç´°ãƒšãƒ¼ã‚¸ï¼‰ | **3h** | Phase C |
| **åˆè¨ˆ** | | **13h** | |

### æ®µéšçš„ãƒ‡ãƒªãƒãƒªãƒ¼

| ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ | Phase | Issue å®Œäº† | æˆæœç‰© |
|---|---|---|---|
| **MS1**: ã‚¹ãƒ ãƒ¼ã‚ºè¡¨ç¤º | A å®Œäº† | Issue #4 å®Œå…¨å®Œäº† | ãƒ•ãƒ©ãƒƒã‚·ãƒ¥è§£æ¶ˆã€å·®åˆ† DOM æ›´æ–° |
| **MS2**: è©±è€…è­˜åˆ¥ MVP | B å®Œäº† | Issue #9 MVP | ConversationTranscriber å‹•ä½œã€ã‚«ãƒ©ãƒ¼ãƒãƒ–ãƒ« |
| **MS3**: è©±è€…ç®¡ç† | C å®Œäº† | Issue #9 ãƒ•ãƒ« | ãƒ©ãƒ™ãƒªãƒ³ã‚°ã€æ°¸ç¶šåŒ– |
| **MS4**: å“è³ªä»•ä¸Šã’ | D å®Œäº† | â€” | è­°äº‹éŒ²é€£æºã€ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å¯¾å¿œ |

**å„ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã”ã¨ã«ãƒ‡ãƒ—ãƒ­ã‚¤ + PR å¯èƒ½** â€” æ®µéšçš„ã«ãƒªãƒªãƒ¼ã‚¹ã§ãã‚‹ã€‚

---

## 8. ãƒªã‚¹ã‚¯ã‚¢ã‚»ã‚¹ãƒ¡ãƒ³ãƒˆ

| ãƒªã‚¹ã‚¯ | ç¢ºç‡ | å½±éŸ¿åº¦ | å¯¾ç­– |
|---|---|---|---|
| Japan East ã§ ConversationTranscriber ãŒéå¯¾å¿œ | Medium | High | East US ã¸ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’æº–å‚™ã€‚Phase A ã¯å½±éŸ¿ãªã— |
| ConversationTranscriber ã®èª²é‡‘ãŒæƒ³å®šä»¥ä¸Š | Medium | Medium | äº‹å‰ã«æ–™é‡‘ç¢ºèªã€‚è©±è€…è­˜åˆ¥ã¯è¨­å®šã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ OFF |
| pause â†’ resume ã§ speakerId ãƒªã‚»ãƒƒãƒˆ | High | Medium | UI ã§åˆ¶é™äº‹é …ã‚’æ˜ç¤ºã€‚segments è‡ªä½“ã¯ä¿æŒã•ã‚Œã‚‹ |
| ConversationTranscriber + ç¿»è¨³ã®åŒæ™‚ä½¿ç”¨ä¸å¯ | ç¢ºå®Ÿ | Low | ç¾è¡Œã®ã€Œèªè­˜å¾Œã«ç¿»è¨³ API å‘¼ã³å‡ºã—ã€æ–¹å¼ã§å¯¾å¿œæ¸ˆã¿ |
| 1000+ segments ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ– | Low | Medium | memo + rAF ã§ååˆ†ã€‚å°†æ¥çš„ã«ä»®æƒ³ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«æ¤œè¨ |
| `segments.map(s => s.text).join(" ")` ã¨æ—§ `transcript` ã®å¾®å·® | Low | High | ãƒ†ã‚¹ãƒˆã§ä¿å­˜/ç¿»è¨³/ã‚³ãƒ”ãƒ¼/è­°äº‹éŒ²ã®å…¨ãƒ‘ã‚¹ã‚’æ¤œè¨¼ |

---

## 9. åˆ¤å®š

### ğŸŸ¢ GO

- Phase Aï¼ˆã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŸºç›¤ï¼‰ã¯ãƒ–ãƒ­ãƒƒã‚«ãƒ¼ãªã—ã€å³æ™‚ç€æ‰‹å¯èƒ½
- Phase B ã¯ Japan East æ¤œè¨¼ãŒå‰æã ãŒã€Phase A ã¨ç‹¬ç«‹ã—ã¦æº–å‚™å¯èƒ½
- çµ±åˆå®Ÿè£…ã«ã‚ˆã‚Š**å·¥æ•°ã‚’20%å‰Šæ¸›**ã€ãƒªã‚°ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ãƒªã‚¹ã‚¯ã‚’**åŠæ¸›**
- æ®µéšçš„ãƒ‡ãƒªãƒãƒªãƒ¼ã«ã‚ˆã‚Šå„ãƒã‚¤ãƒ«ã‚¹ãƒˆãƒ¼ãƒ³ã§ç‹¬ç«‹ã—ã¦ãƒªãƒªãƒ¼ã‚¹å¯èƒ½
- å¾Œæ–¹äº’æ›æ€§ã«ã‚ˆã‚Šä¿å­˜ãƒ»ç¿»è¨³ãƒ»ã‚³ãƒ”ãƒ¼ãƒ»è­°äº‹éŒ²ãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã®æ—¢å­˜æ©Ÿèƒ½ã«å½±éŸ¿ãªã—
