# Issue #126: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIè£œæ­£ â€” å®Ÿè£…è¨ˆç”»æ›¸

## ğŸ“‹ æ¦‚è¦

éŒ²éŸ³ä¸­ã«ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆã‚’LLMã§è£œæ­£ã™ã‚‹æ©Ÿèƒ½ã€‚  
AI Cuesï¼ˆIssue #89ï¼‰ã§å®Ÿç¸¾ã®ã‚ã‚‹ã€Œãƒãƒƒãƒ + ãƒ‡ãƒã‚¦ãƒ³ã‚¹ã€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è»¢ç”¨ã—ã€ã‚¢ãƒ—ãƒ­ãƒ¼ãƒBï¼ˆ5ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã”ã¨ã®ãƒãƒƒãƒè£œæ­£ï¼‰ã§å®Ÿè£…ã™ã‚‹ã€‚

**ã‚³ã‚¹ãƒˆ**: $0.014/ä¼šè­°ï¼ˆgpt-4o-miniï¼‰  
**ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 5ã€œ10ç§’ï¼ˆãƒãƒƒãƒè“„ç© + APIå¿œç­”ï¼‰  
**è¦‹ç©ã‚Šå·¥æ•°**: 17h

---

## ğŸ—ï¸ å¤‰æ›´ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

### æ–°è¦ä½œæˆ

| # | ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|---|---------|------|
| 1 | `api/src/functions/realtimeCorrection.ts` | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ |
| 2 | `web/src/services/correctionApi.ts` | ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰APIã‚µãƒ¼ãƒ“ã‚¹ |
| 3 | `web/src/hooks/useRealtimeCorrection.ts` | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£ãƒ•ãƒƒã‚¯ |

### å¤‰æ›´

| # | ãƒ•ã‚¡ã‚¤ãƒ« | å†…å®¹ |
|---|---------|------|
| 4 | `web/src/types/index.ts` | `LiveSegment` ã« `correctedText`, `isCorrected` è¿½åŠ ; `UserSettings` ã« `enableRealtimeCorrection` è¿½åŠ  |
| 5 | `web/src/hooks/useSpeechRecognition.ts` | `updateSegment` ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  |
| 6 | `web/src/hooks/useTranslationRecognizer.ts` | `updateSegment` ãƒ¡ã‚½ãƒƒãƒ‰è¿½åŠ  |
| 7 | `web/src/hooks/index.ts` | ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆè¿½åŠ  |
| 8 | `web/src/app/page.tsx` | ãƒ•ãƒƒã‚¯çµ±åˆã€UIè¡¨ç¤ºã€ä¿å­˜æ™‚çµ±åˆ |

---

## ğŸ“ å®Ÿè£…æ‰‹é †

### Step 1: API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä½œæˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `api/src/functions/realtimeCorrection.ts`

```typescript
import {
  app,
  HttpRequest,
  HttpResponseInit,
  InvocationContext,
} from "@azure/functions";
import { AzureOpenAI } from "openai";

interface RealtimeCorrectionRequest {
  segments: Array<{ id: string; text: string }>;
  language: string;
  phraseList?: string[];
}

interface CorrectionItem {
  id: string;
  original: string;
  corrected: string;
}

interface CorrectionResponse {
  corrections: CorrectionItem[];
}

const REALTIME_CORRECTION_PROMPT = `ã‚ãªãŸã¯éŸ³å£°èªè­˜çµæœã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ ¡æ­£ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸè¤‡æ•°ã®ç™ºè¨€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã—ã€æ˜ã‚‰ã‹ãªèª¤èªè­˜ã®ã¿ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

ã€ä¿®æ­£ã™ã¹ãã‚‚ã®ã€‘
- åŒéŸ³ç•°ç¾©èªã®èª¤ã‚Šï¼ˆä¾‹ï¼šã€Œæ©Ÿé–¢ã€â†’ã€ŒæœŸé–“ã€ã€ã€Œä»¥ä¸Šã€â†’ã€Œç•°å¸¸ã€ï¼‰
- æ˜ã‚‰ã‹ãªèãé–“é•ã„
- ä¸è‡ªç„¶ãªå˜èªã®åŒºåˆ‡ã‚Š
- å›ºæœ‰åè©ã®èª¤èªè­˜ï¼ˆæ–‡è„ˆã‹ã‚‰æ¨æ¸¬å¯èƒ½ãªå ´åˆï¼‰

ã€ä¿®æ­£ã—ã¦ã¯ã„ã‘ãªã„ã‚‚ã®ã€‘
- è©±è€…ã®æ„å›³ã‚„å†…å®¹ã‚’å¤‰ãˆã‚‹
- æ–‡ä½“ã‚„å£èª¿ï¼ˆè©±ã—è¨€è‘‰ã®ã¾ã¾ï¼‰
- æ–‡æ³•çš„ã«æ­£ã—ã„è¡¨ç¾ã¸ã®æ›¸ãæ›ãˆ
- ä¿®æ­£ä¸è¦ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆ

JSONå½¢å¼ã§å‡ºåŠ›:
{
  "corrections": [
    { "id": "ã‚»ã‚°ãƒ¡ãƒ³ãƒˆID", "original": "åŸæ–‡", "corrected": "è£œæ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆ" }
  ]
}

ä¿®æ­£ãŒä¸è¦ãªå ´åˆã¯ "corrections": [] ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
ä¿®æ­£ãŒã‚ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚`;

function jsonResponse<T>(
  data: { success: boolean; data?: T; error?: string },
  status: number = 200
): HttpResponseInit {
  return {
    status,
    headers: {
      "Content-Type": "application/json",
      "Access-Control-Allow-Origin": "*",
      "Access-Control-Allow-Methods": "POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type, Authorization",
    },
    body: JSON.stringify(data),
  };
}

app.http("realtimeCorrection", {
  methods: ["POST", "OPTIONS"],
  authLevel: "anonymous",
  route: "correction/realtime",
  handler: async (
    request: HttpRequest,
    _context: InvocationContext
  ): Promise<HttpResponseInit> => {
    if (request.method === "OPTIONS") {
      return jsonResponse({ success: true });
    }

    try {
      const body = (await request.json()) as RealtimeCorrectionRequest;

      if (!body.segments || body.segments.length === 0) {
        return jsonResponse(
          { success: false, error: "segments array is required" },
          400
        );
      }

      const endpoint = process.env.AZURE_OPENAI_ENDPOINT;
      const apiKey = process.env.AZURE_OPENAI_KEY;
      const deploymentName =
        process.env.AZURE_OPENAI_CORRECTION_DEPLOYMENT_NAME ||
        process.env.AZURE_OPENAI_DEPLOYMENT_NAME ||
        "gpt-4o-mini";

      if (!endpoint || !apiKey) {
        return jsonResponse(
          { success: false, error: "Azure OpenAI is not configured" },
          500
        );
      }

      // è¨€èªæŒ‡ç¤º
      const langInstruction = body.language?.startsWith("ja")
        ? ""
        : `\n\nå‡ºåŠ›ã¯å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã¨åŒã˜è¨€èªã§è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚`;

      // ãƒ•ãƒ¬ãƒ¼ã‚ºãƒªã‚¹ãƒˆè¿½åŠ ï¼ˆç²¾åº¦å‘ä¸Šï¼‰
      const phraseHint = body.phraseList?.length
        ? `\n\nã€å‚è€ƒ: ã‚ˆãä½¿ã‚ã‚Œã‚‹å›ºæœ‰åè©ãƒ»å°‚é–€ç”¨èªã€‘\n${body.phraseList.join("ã€")}`
        : "";

      const systemPrompt =
        REALTIME_CORRECTION_PROMPT + langInstruction + phraseHint;

      const segmentsText = body.segments
        .map((s) => `[${s.id}] ${s.text}`)
        .join("\n");

      const client = new AzureOpenAI({
        endpoint,
        apiKey,
        apiVersion: "2024-08-01-preview",
      });

      const response = await client.chat.completions.create({
        model: deploymentName,
        messages: [
          { role: "system", content: systemPrompt },
          { role: "user", content: `ä»¥ä¸‹ã®ç™ºè¨€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n\n${segmentsText}` },
        ],
        temperature: 0.2,
        max_tokens: 2000,
        response_format: { type: "json_object" },
      });

      const content = response.choices[0]?.message?.content;
      if (!content) {
        return jsonResponse(
          { success: false, error: "No response from OpenAI" },
          500
        );
      }

      const parsed = JSON.parse(content) as CorrectionResponse;

      return jsonResponse<CorrectionResponse>({
        success: true,
        data: { corrections: parsed.corrections || [] },
      });
    } catch (error) {
      return jsonResponse(
        { success: false, error: (error as Error).message },
        500
      );
    }
  },
});
```

---

### Step 2: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ API ã‚µãƒ¼ãƒ“ã‚¹

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/services/correctionApi.ts`

```typescript
import { ApiResponse } from "@/types";

const API_BASE_URL =
  process.env.NEXT_PUBLIC_API_URL ||
  "https://func-airecorder-dev.azurewebsites.net/api";

export interface RealtimeCorrectionInput {
  segments: Array<{ id: string; text: string }>;
  language: string;
  phraseList?: string[];
}

export interface CorrectionItem {
  id: string;
  original: string;
  corrected: string;
}

export interface CorrectionApiResponse {
  corrections: CorrectionItem[];
}

class CorrectionApiService {
  private baseUrl: string;

  constructor() {
    this.baseUrl = API_BASE_URL;
  }

  async correctSegments(
    input: RealtimeCorrectionInput,
    signal?: AbortSignal
  ): Promise<ApiResponse<CorrectionApiResponse>> {
    const url = `${this.baseUrl}/correction/realtime`;

    try {
      const response = await fetch(url, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(input),
        signal,
      });

      const text = await response.text();
      let data: Record<string, unknown> | null = null;

      if (text) {
        try {
          data = JSON.parse(text);
        } catch {
          return { error: `JSON parse error: ${text.substring(0, 100)}` };
        }
      }

      if (!response.ok) {
        return {
          error: (data?.error as string) || `HTTP error ${response.status}`,
        };
      }

      return { data: data?.data as CorrectionApiResponse };
    } catch (err) {
      if ((err as Error).name === "AbortError") {
        return { error: "REQUEST_ABORTED" };
      }
      return { error: (err as Error).message };
    }
  }
}

export const correctionApi = new CorrectionApiService();
```

---

### Step 3: `LiveSegment` å‹æ‹¡å¼µ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/types/index.ts`

`LiveSegment` ã«ä»¥ä¸‹ã‚’è¿½åŠ :

```typescript
export interface LiveSegment {
  id: string;
  text: string;
  speaker?: string;
  speakerLabel?: string;
  timestamp: number;
  duration?: number;
  // â˜… Issue #126: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIè£œæ­£
  correctedText?: string;    // è£œæ­£å¾Œãƒ†ã‚­ã‚¹ãƒˆ
  isCorrected?: boolean;     // è£œæ­£æ¸ˆã¿ãƒ•ãƒ©ã‚°
}
```

`UserSettings` ã«ä»¥ä¸‹ã‚’è¿½åŠ :

```typescript
export interface UserSettings {
  // ... æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ ...
  enableRealtimeCorrection?: boolean;  // â˜… Issue #126
}
```

---

### Step 4: `useSpeechRecognition` ã« `updateSegment` è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useSpeechRecognition.ts`

è¿”ã‚Šå€¤ã« `updateSegment` ãƒ¡ã‚½ãƒƒãƒ‰ã‚’è¿½åŠ :

```typescript
const updateSegment = useCallback((segmentId: string, patch: Partial<LiveSegment>) => {
  setSegments(prev => prev.map(seg =>
    seg.id === segmentId ? { ...seg, ...patch } : seg
  ));
}, []);

// return ã«è¿½åŠ 
return {
  // ... æ—¢å­˜ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ ...
  updateSegment,
};
```

Interface `UseSpeechRecognitionReturn` ã«ã‚‚è¿½åŠ :

```typescript
interface UseSpeechRecognitionReturn {
  // ... æ—¢å­˜ ...
  updateSegment: (segmentId: string, patch: Partial<LiveSegment>) => void;
}
```

---

### Step 5: `useTranslationRecognizer` ã«åŒæ§˜ã® `updateSegment` è¿½åŠ 

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useTranslationRecognizer.ts`

Step 4 ã¨åŒã˜ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚

---

### Step 6: `useRealtimeCorrection` ãƒ•ãƒƒã‚¯

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/hooks/useRealtimeCorrection.ts`

```typescript
"use client";

import { useState, useEffect, useRef, useCallback } from "react";
import { LiveSegment } from "@/types";
import { correctionApi } from "@/services/correctionApi";

// â”€â”€â”€ è¨­å®šå®šæ•° â”€â”€â”€
const BATCH_SIZE = 5;
const DEBOUNCE_MS = 3000;
const MAX_CALLS_PER_SESSION = 50;
const CONTEXT_WINDOW = 10;

export interface UseRealtimeCorrectionOptions {
  segments: LiveSegment[];
  language: string;
  enabled: boolean;
  isRecording: boolean;
  phraseList?: string[];
  onCorrection: (corrections: Array<{ segmentId: string; correctedText: string }>) => void;
}

export interface UseRealtimeCorrectionReturn {
  isCorrecting: boolean;
  correctionCount: number;
  correctedSegmentCount: number;
  error: string | null;
}

export function useRealtimeCorrection({
  segments,
  language,
  enabled,
  isRecording,
  phraseList = [],
  onCorrection,
}: UseRealtimeCorrectionOptions): UseRealtimeCorrectionReturn {
  const [isCorrecting, setIsCorrecting] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [correctionCount, setCorrectionCount] = useState(0);
  const [correctedSegmentCount, setCorrectedSegmentCount] = useState(0);

  const segmentsRef = useRef(segments);
  segmentsRef.current = segments;

  const onCorrectionRef = useRef(onCorrection);
  onCorrectionRef.current = onCorrection;

  const lastProcessedIndexRef = useRef(0);
  const callCountRef = useRef(0);
  const debounceTimerRef = useRef<NodeJS.Timeout | null>(null);
  const abortControllerRef = useRef<AbortController | null>(null);

  // ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹æ™‚ã«ãƒªã‚»ãƒƒãƒˆ
  useEffect(() => {
    if (isRecording) {
      setError(null);
      setCorrectionCount(0);
      setCorrectedSegmentCount(0);
      lastProcessedIndexRef.current = 0;
      callCountRef.current = 0;
    }
  }, [isRecording]);

  // ã‚¢ãƒ³ãƒã‚¦ãƒ³ãƒˆæ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
  useEffect(() => {
    return () => {
      if (debounceTimerRef.current) clearTimeout(debounceTimerRef.current);
      if (abortControllerRef.current) abortControllerRef.current.abort();
    };
  }, []);

  // ã‚³ã‚¢APIå‘¼ã³å‡ºã—
  const fetchCorrections = useCallback(
    async (targetSegments: LiveSegment[]) => {
      if (callCountRef.current >= MAX_CALLS_PER_SESSION) return;

      if (abortControllerRef.current) abortControllerRef.current.abort();
      const controller = new AbortController();
      abortControllerRef.current = controller;

      setIsCorrecting(true);
      setError(null);
      callCountRef.current += 1;
      setCorrectionCount(callCountRef.current);

      try {
        const response = await correctionApi.correctSegments(
          {
            segments: targetSegments.map(s => ({ id: s.id, text: s.text })),
            language,
            phraseList: phraseList.length > 0 ? phraseList : undefined,
          },
          controller.signal
        );

        if (controller.signal.aborted) return;

        if (response.error) {
          if (response.error !== "REQUEST_ABORTED") {
            setError(response.error);
          }
          return;
        }

        if (response.data?.corrections && response.data.corrections.length > 0) {
          const mappedCorrections = response.data.corrections.map(c => ({
            segmentId: c.id,
            correctedText: c.corrected,
          }));
          onCorrectionRef.current(mappedCorrections);
          setCorrectedSegmentCount(prev => prev + mappedCorrections.length);
        }
      } catch {
        // Network error â€” silent failure
      } finally {
        setIsCorrecting(false);
        abortControllerRef.current = null;
      }
    },
    [language, phraseList]
  );

  // ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç›£è¦– â†’ ãƒãƒƒãƒ + ãƒ‡ãƒã‚¦ãƒ³ã‚¹
  useEffect(() => {
    if (!enabled || !isRecording) return;
    if (callCountRef.current >= MAX_CALLS_PER_SESSION) return;

    const newCount = segments.length - lastProcessedIndexRef.current;
    if (newCount < BATCH_SIZE) return;

    if (debounceTimerRef.current) clearTimeout(debounceTimerRef.current);

    debounceTimerRef.current = setTimeout(() => {
      const current = segmentsRef.current;
      // æœªè£œæ­£ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿å¯¾è±¡
      const startIdx = Math.max(0, current.length - CONTEXT_WINDOW);
      const targetSegments = current.slice(startIdx).filter(s => !s.isCorrected);

      if (targetSegments.length > 0) {
        lastProcessedIndexRef.current = current.length;
        fetchCorrections(targetSegments);
      }
    }, DEBOUNCE_MS);

    return () => {
      if (debounceTimerRef.current) clearTimeout(debounceTimerRef.current);
    };
  }, [segments.length, enabled, isRecording, fetchCorrections]);

  // éŒ²éŸ³åœæ­¢æ™‚ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«
  useEffect(() => {
    if (!isRecording) {
      if (abortControllerRef.current) abortControllerRef.current.abort();
      if (debounceTimerRef.current) clearTimeout(debounceTimerRef.current);
    }
  }, [isRecording]);

  return {
    isCorrecting,
    correctionCount,
    correctedSegmentCount,
    error,
  };
}
```

---

### Step 7: `page.tsx` çµ±åˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `web/src/app/page.tsx`

#### 7a. ãƒ•ãƒƒã‚¯å‘¼ã³å‡ºã—è¿½åŠ 

AI Cues ã®ç›´å¾Œã«é…ç½®:

```typescript
// Issue #126: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIè£œæ­£
const enableRealtimeCorrection = settings.enableRealtimeCorrection ?? false;
const {
  isCorrecting,
  correctionCount,
  correctedSegmentCount,
  error: correctionError,
} = useRealtimeCorrection({
  segments,
  language: sourceLanguage,
  enabled: enableRealtimeCorrection,
  isRecording: showRecordingUI,
  phraseList: settings.phraseList ?? [],
  onCorrection: useCallback((corrections) => {
    for (const { segmentId, correctedText } of corrections) {
      if (translationMode === "sdk") {
        sdkUpdateSegment(segmentId, { correctedText, isCorrected: true });
      } else {
        apiUpdateSegment(segmentId, { correctedText, isCorrected: true });
      }
    }
  }, [translationMode]),
});
```

#### 7b. errors é…åˆ—ã«è¿½åŠ 

```typescript
const errors = [speechError, translationError, ttsError, audioError, fsmError, correctionError]
  .filter(Boolean) as string[];
```

#### 7c. æ–‡å­—èµ·ã“ã—è¡¨ç¤ºã§ correctedText ã‚’å„ªå…ˆ

`labeledSegments` ã® useMemo ã§ã€è¡¨ç¤ºãƒ†ã‚­ã‚¹ãƒˆã« `correctedText` ã‚’é©ç”¨:

```typescript
const labeledSegments = useMemo(() => {
  return segments.map((seg) => ({
    ...seg,
    // ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°å„ªå…ˆè¡¨ç¤º
    text: seg.correctedText || seg.text,
    speakerLabel: enableSpeakerDiarization && seg.speaker
      ? getSpeakerLabel(seg.speaker)
      : undefined,
  }));
}, [segments, enableSpeakerDiarization, getSpeakerLabel]);
```

#### 7d. ä¿å­˜æ™‚ã«è£œæ­£ãƒ†ã‚­ã‚¹ãƒˆã‚’çµ±åˆ

`handleSaveWithTitle` å†…ã® `fullText` ã‚’è£œæ­£ç‰ˆã§æ§‹æˆ:

```typescript
const finalTranscript = labeledSegments.map(seg => seg.text).join(" ");
// ...
transcript: {
  segments: labeledSegments.map((seg, i) => ({
    // ...æ—¢å­˜...
    text: seg.correctedText || seg.text,  // è£œæ­£ç‰ˆãƒ†ã‚­ã‚¹ãƒˆ
  })),
  fullText: finalTranscript,
},
```

#### 7e. UI ã«ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼è¿½åŠ 

éŒ²éŸ³ä¸­ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒãƒ¼ã«è£œæ­£çŠ¶æ³ã‚’è¡¨ç¤º:

```tsx
{enableRealtimeCorrection && showRecordingUI && (
  <div className="flex items-center gap-1 text-xs text-purple-500">
    {isCorrecting && <Loader2 className="h-3 w-3 animate-spin" />}
    <span>âœ¨ AIè£œæ­£: {correctedSegmentCount}ä»¶ä¿®æ­£ ({correctionCount}å›)</span>
  </div>
)}
```

---

### Step 8: è¨­å®šç”»é¢ã« ON/OFF è¿½åŠ 

è¨­å®šç”»é¢ï¼ˆ`web/src/app/settings/page.tsx` ç­‰ï¼‰ã«ä»¥ä¸‹ã®ãƒˆã‚°ãƒ«ã‚’è¿½åŠ :

```tsx
<label className="flex items-center gap-2">
  <Switch
    checked={settings.enableRealtimeCorrection ?? false}
    onCheckedChange={(v) => updateSettings({ enableRealtimeCorrection: v })}
  />
  <span>ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ AIè£œæ­£ï¼ˆéŒ²éŸ³ä¸­ã«æ–‡å­—èµ·ã“ã—ã‚’è‡ªå‹•è£œæ­£ï¼‰</span>
</label>
```

---

## âš ï¸ æ³¨æ„äº‹é …

### AI Cues ã¨ã®ç«¶åˆå›é¿

AI Cues ã¨ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£ã®ä¸¡æ–¹ãŒ ON ã®å ´åˆã€Azure OpenAI ã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒç´„2å€ã«ãªã‚‹ã€‚

**å¯¾ç­–**:
1. ä¸¡æ–¹æœ‰åŠ¹æ™‚ã¯ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£ã® `DEBOUNCE_MS` ã‚’ `5000` ã«å»¶é•·
2. `MAX_CALLS_PER_SESSION` ã‚’ `30` ã«ç¸®å°
3. UI ã§ã€ŒAI Cues ã¨è£œæ­£ã¯æ’ä»–æ¨å¥¨ã€ã®ãƒ’ãƒ³ãƒˆè¡¨ç¤º

### ä¿å­˜å¾Œãƒãƒƒãƒè£œæ­£ã¨ã®çµ±åˆ

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è£œæ­£æ¸ˆã¿ã®éŒ²éŸ³ã‚’ä¿å­˜ã™ã‚‹éš›:
- `correctionStatus: "realtime-completed"` ã‚’è¨­å®š
- ä¿å­˜å¾Œã®ãƒãƒƒãƒè£œæ­£ã¯ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã§ã‚¹ã‚­ãƒƒãƒ—
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ‰‹å‹•ã§ã€Œå†è£œæ­£ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸå ´åˆã®ã¿ãƒãƒƒãƒè£œæ­£ã‚’å®Ÿè¡Œ

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆç¢ºèªé …ç›®

| # | ãƒ†ã‚¹ãƒˆ | æœŸå¾…çµæœ |
|---|--------|---------|
| 1 | enableRealtimeCorrection=false | è£œæ­£APIãŒå‘¼ã°ã‚Œãªã„ |
| 2 | 5ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè“„ç© | 3ç§’å¾Œã«APIå‘¼ã³å‡ºã— |
| 3 | è£œæ­£çµæœã®è¡¨ç¤º | ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ†ã‚­ã‚¹ãƒˆãŒæ›´æ–°ã•ã‚Œã‚‹ |
| 4 | è£œæ­£çµæœãªã—ï¼ˆä¿®æ­£ä¸è¦ï¼‰ | ç©ºé…åˆ—ã€UIã«å¤‰åŒ–ãªã— |
| 5 | API ã‚¨ãƒ©ãƒ¼ | errorè¡¨ç¤ºã€åŸæ–‡ä¿æŒ |
| 6 | 50å›ä¸Šé™åˆ°é” | ä»¥é™ã®å‘¼ã³å‡ºã—ã‚¹ã‚­ãƒƒãƒ— |
| 7 | éŒ²éŸ³åœæ­¢ | é€²è¡Œä¸­ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚­ãƒ£ãƒ³ã‚»ãƒ« |
| 8 | ä¿å­˜ â†’ è£œæ­£ãƒ†ã‚­ã‚¹ãƒˆä¿æŒ | correctedText ãŒ fullText ã«çµ±åˆ |
| 9 | AI Cues åŒæ™‚ON | ãƒ¬ãƒ¼ãƒˆãƒªãƒŸãƒƒãƒˆè¶…éã—ãªã„ |

---

*è¨ˆç”»ä½œæˆæ—¥: 2026-02-17*
*è¨ˆç”»è€…: ReviewAAgent*
